{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привет, у меня трудности по преобразованию данных, неполучается подготовить их чтобы начать тренировать модель. Мне кажется проблема в типе данных, но я не уверен что именно. Если можно немого фидбека, Спасибо!!!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project with BERT\n",
    "reference (https://gist.github.com/albahnsen/b02d2183c93067e3f248a428430c970e)\n",
    "# Project Goal (Цель Проекта) \n",
    "We are given a file with Twitter comments. Those comments are marked as positive/negative. We need to build a NLP model that will be able to predict the \"toxicity\" of comments with a minimum of 0.75 F1 Score. <br/><br/>\n",
    "Нам дан файл с комментариями с Твитера. Они помеченны как позитивные/негативные. Нам требуется построить NLP модель которая сможет предсказать токсичность комментариев с минимальной оценкой 0.75 по F1 Score."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Outline (План Проекта)\n",
    "1. Project Goal (Цель Проекта)\n",
    "2. Outline  (План)\n",
    "3. Libraries/Data Load  (Библеотеки/Выгрузка Данных)\n",
    "4. Data Inspection/Data Preprocessing  (Исследовательский Анализ/Предобработка данных)\n",
    "5. Training Pipeline + Logistic Regression  (Фунция для Оптимизяции Обучения + Простой Регрессор)\n",
    "6. Try Out the Training Pipeline with Other Logistic ML Models  (Исследование Других Моделей)\n",
    "7. Results  (Вывод)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries/Data Load  (Библеотеки/Выгрузка Данных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import logging\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.set_verbosity_warning()\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = './datasets/toxic_comments.csv'\n",
    "web_path = '/datasets/toxic_comments.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(local_path):\n",
    "  df = pd.read_csv(local_path)\n",
    "elif os.path.exists(web_path):\n",
    "  df = pd.read_csv(web_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Inspection/Data Preprocessing \n",
    "# (Исследовательский Анализ/Предобработка данных)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual inspection of data showed that most of the comments are of english language. So far we can assume we will be using BERT tokenizer and BERT model \"bert-base-uncased\". <br/><br/>\n",
    "После визуального исследования данных, ясно что мы работаем с английскими комментариями. Значит будем исползовать 'bert-base-uncased'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159292, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also important to inspect the ratio of \"positive/negative\" target feature, we need to have a good balance while training the model 50/50. <br/><br/>\n",
    "Надо тоже имметь ввиду распределения \"позитивные/негативные\" варианты для целегого признака. Нам нужно хорошее распределение 50/50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic to all comments ratio: 0.10161213369158527\n"
     ]
    }
   ],
   "source": [
    "print(\"toxic to all comments ratio: {}\".format(df.toxic.sum()/df.shape[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratio issue will be solved in the training pipeline. <br/><br/>\n",
    "Проблемма соотношения будет решенна в функции обучения."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline + Logistic Regression  \n",
    "# (Фунция для Оптимизяции Обучения + Простой Регрессор)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizing training process - iterative model training and testing will let us know when to stop vectorizing the data.\n",
    "In order to do that we need to create an instance of class that can hold vectorized train/test data, and when needed to perform those vectorizations in batch format. <br/><br/>\n",
    "Оптимизация обучения - постепенное обучение и тестирование модели поможет нам понять когда можно перестать векторизировать данные. Для этого мы создадим класс который будет держать векторизированные данные, и векторизировать их по надобности, в зависсимости от размера батча."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We touched on the problem of positive/negative target feature ratio. Our class will handle it by first processing positive/negative data with 50/50 ratio, then if needed processing the rest of the data. <br/><br/>\n",
    "Проблема с соотношением позитивного/негативного соотношения целегого признака будет решенна следующим образом: сначала обрабатываем все данные с соотношением 50/50 потом обрабатывем и подаем все осталные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extracting_embeddings(text):\n",
    "      tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "      model = BertModel.from_pretrained('bert-base-uncased')\n",
    "      model.eval()\n",
    "\n",
    "      marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "      # Tokenize our sentence with the BERT tokenizer\n",
    "      tokenized_text = tokenizer.tokenize(marked_text)\n",
    "      \n",
    "      # Truncate the text\n",
    "      truncated_text = tokenized_text[:512]\n",
    "\n",
    "      # Map the token strings to their vocabulary indices\n",
    "      indexed_tokens = tokenizer.convert_tokens_to_ids(truncated_text)\n",
    "\n",
    "      # Pad the text\n",
    "      indexed_tokens = indexed_tokens + [0] * (512 - len(indexed_tokens))\n",
    "\n",
    "      # Attention mask\n",
    "      attention_mask = np.where(np.array(indexed_tokens) != 0, 1, 0)\n",
    "\n",
    "      # Convert inputs to PyTorch tensors\n",
    "      tokens_tensor = torch.tensor([np.array(indexed_tokens)])\n",
    "      attention_mask = torch.tensor([np.array(attention_mask)])\n",
    "\n",
    "      # Predict hidden states features for each layer\n",
    "      with torch.no_grad():\n",
    "        encoded_layers = model(tokens_tensor, attention_mask=attention_mask)\n",
    "\n",
    "      return np.concatenate(encoded_layers.last_hidden_state.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "hello = extracting_embeddings('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3060987 ,  0.2622295 , -0.18961759, ..., -0.1651108 ,\n",
       "         0.10138296,  0.41190478],\n",
       "       [-0.73901165, -0.03363602,  0.39322147, ..., -0.18180817,\n",
       "        -0.18388468, -0.21847823],\n",
       "       [ 0.58008885,  0.06270907, -0.26372138, ...,  0.39631116,\n",
       "        -0.56836987, -0.49243015],\n",
       "       ...,\n",
       "       [-0.6366559 , -0.04542178,  0.40899047, ..., -0.01840694,\n",
       "         0.20758131,  0.04689681],\n",
       "       [-0.7131955 , -0.13211566,  0.29559928, ..., -0.00647255,\n",
       "         0.280729  , -0.02023812],\n",
       "       [-0.47300822, -0.00674867,  0.48973006, ...,  0.02761357,\n",
       "         0.19655119,  0.03328196]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertDataPipeline:\n",
    "  def __init__(self, df, batch_size):\n",
    "    self.batch_size = batch_size\n",
    "    self.current_batch = 0\n",
    "\n",
    "    # optimize data for the ratio\n",
    "    positive = df[df.toxic == 1]\n",
    "    negative = df[df.toxic == 0]\n",
    "    negative_in = negative.loc[:positive.shape[0]]\n",
    "    negative_out = negative.loc[positive.shape[0]:]\n",
    "    balanced = pd.concat([positive, negative_in], axis=0).reset_index(drop=True)\n",
    "    balanced = balanced.sample(frac=1).reset_index(drop=True)\n",
    "    self.df = pd.concat([balanced, negative_out], axis=0).reset_index(drop=True) # the balanced will come first\n",
    "\n",
    "    self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    self.model = BertModel.from_pretrained('bert-base-uncased')\n",
    "    self.model.eval()\n",
    "\n",
    "    self.train = pd.DataFrame({'vectorized':[], 'toxic':[]})\n",
    "    self.test = pd.DataFrame({'vectorized':[], 'toxic':[]})\n",
    "  \n",
    "  def data_train_new(self):\n",
    "    def extracting_embeddings(text):\n",
    "      marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "      # Tokenize our sentence with the BERT tokenizer\n",
    "      tokenized_text = self.tokenizer.tokenize(marked_text)\n",
    "      \n",
    "      # Truncate the text\n",
    "      truncated_text = tokenized_text[:512]\n",
    "\n",
    "      # Map the token strings to their vocabulary indices\n",
    "      indexed_tokens = self.tokenizer.convert_tokens_to_ids(truncated_text)\n",
    "\n",
    "      # Pad the text\n",
    "      indexed_tokens = indexed_tokens + [0] * (512 - len(indexed_tokens))\n",
    "\n",
    "      # Attention mask\n",
    "      attention_mask = np.where(np.array(indexed_tokens) != 0, 1, 0)\n",
    "\n",
    "      # Convert inputs to PyTorch tensors\n",
    "      tokens_tensor = torch.tensor([np.array(indexed_tokens)])\n",
    "      attention_mask = torch.tensor([np.array(attention_mask)])\n",
    "\n",
    "      # Predict hidden states features for each layer\n",
    "      with torch.no_grad():\n",
    "        encoded_layers = self.model(tokens_tensor, attention_mask=attention_mask)\n",
    "\n",
    "      return np.concatenate(encoded_layers.last_hidden_state.numpy())\n",
    "\n",
    "    # train data\n",
    "    df_slice_train = self.df.loc[self.batch_size*self.current_batch:self.batch_size*(self.current_batch + 1)]\n",
    "    self.current_batch += 1\n",
    "\n",
    "    x_train = df_slice_train.text\n",
    "    x_train = x_train.apply(lambda x: extracting_embeddings(x))\n",
    "    y_train = df_slice_train.toxic\n",
    "\n",
    "    self.train = pd.concat([self.train, pd.DataFrame({'vectorized': x_train, 'toxic': y_train})], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # test data\n",
    "    df_slice_test = self.df.loc[self.batch_size*self.current_batch:self.batch_size*(self.current_batch + 1)]\n",
    "    self.current_batch += 1\n",
    "\n",
    "    x_test = df_slice_test.text\n",
    "    x_test = x_test.apply(lambda x: extracting_embeddings(x))\n",
    "    y_test = df_slice_test.toxic\n",
    "\n",
    "    self.test = pd.concat([self.test, pd.DataFrame({'vectorized': x_test, 'toxic': y_test})], axis=0).reset_index(drop=True)\n",
    "\n",
    "    # return new training data\n",
    "    return pd.DataFrame({'vectorized':x_train, 'toxic':y_train})\n",
    "\n",
    "  def data_train(self):\n",
    "    return self.train\n",
    "  \n",
    "  def data_test(self):\n",
    "    return self.test    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(bertDataPipeline, model, limit_seconds, f1_score_min):\n",
    "  time_start = time()\n",
    "  f1_score_best = 0\n",
    "  initial_learn = True\n",
    "\n",
    "  while (time() - time_start < limit_seconds):\n",
    "    # exit condition - meet the score requirements, or time limit ^^^\n",
    "    # (also if we run out of data - unlikely, not to worry about, it would also take too long to vectorize all that data)\n",
    "\n",
    "    if f1_score_best >= f1_score_min:\n",
    "      break\n",
    "\n",
    "    if initial_learn:\n",
    "      initial_learn = False\n",
    "      if bertDataPipeline.data_train().shape[0] > 0:\n",
    "        df_train = bertDataPipeline.data_train()\n",
    "        print(df_train.head())\n",
    "        model.fit(df_train.vectorized, df_train.toxic)\n",
    "        df_test = bertDataPipeline.data_test()\n",
    "        z_test = model.predict(df_test.vectorized)\n",
    "        y_test = df_test.toxic\n",
    "        f1_score_current = f1_score(y_test, z_test)\n",
    "        if f1_score_current > f1_score_best:\n",
    "          f1_score_best = f1_score_current\n",
    "    else:\n",
    "      df_train = bertDataPipeline.data_train_new()\n",
    "      print(df_train.head())\n",
    "      model.fit(df_train.vectorized, df_train.toxic)\n",
    "      df_test = bertDataPipeline.data_test()\n",
    "      z_test = model.predict(df_test.vectorized)\n",
    "      y_test = df_test.toxic\n",
    "      f1_score_current = f1_score(y_test, z_test)\n",
    "      if f1_score_current > f1_score_best:\n",
    "        f1_score_best = f1_score_current\n",
    "  \n",
    "  print('best f1_score {}'.format(f1_score_best))\n",
    "  print('time to train {}s'.format(time() - time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertDataPipeline = BertDataPipeline(df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_linear_model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          vectorized  toxic\n",
      "0  [[-0.107602015, 0.42301303, 0.07229452, -0.567...      0\n",
      "1  [[0.19171593, -0.09149636, -0.33626673, -0.082...      1\n",
      "2  [[0.117458366, -0.10120446, -0.13708822, -0.56...      1\n",
      "3  [[-0.9321038, 0.0019665472, -0.0461475, -0.515...      0\n",
      "4  [[-0.15104553, 0.081879444, -0.080407724, -0.5...      1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sc/09svshb15mg04p30bkrrq31w0000gn/T/ipykernel_49508/1282537418.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbertDataPipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogistic_linear_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/sc/09svshb15mg04p30bkrrq31w0000gn/T/ipykernel_49508/2462268174.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(bertDataPipeline, model, limit_seconds, f1_score_min)\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbertDataPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_train_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoxic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m       \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbertDataPipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0mz_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1506\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1509\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 964\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m    965\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    744\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 746\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    747\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    870\u001b[0m               dtype='datetime64[ns]')\n\u001b[1;32m    871\u001b[0m         \"\"\"\n\u001b[0;32m--> 872\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[0;31m# ----------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "train_model(bertDataPipeline, logistic_linear_model, 120, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45703e4c639f55edd07b7934093f007f2bf0e2096adf152af19818193a1ac5d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
